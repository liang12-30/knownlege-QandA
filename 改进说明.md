# 系统改进说明

## 📋 用户提出的问题

1. **答非所问**：虽然相关度高，但答案不够准确
2. **缺少来源信息**：无法知道答案来自哪个文档
3. **.doc文档未读取**：65篇文档中2篇.doc格式未成功解析
4. **模型测试需求**：要求测试 BGE、Sentence-BERT、SimCSE 等模型

---

## ✅ 已完成的改进

### 1. 实现BM25+语义混合检索（解决答非所问）

**问题分析：**
- 纯向量检索容易出现语义相似但实际不相关的结果
- 缺少词频匹配，无法精准定位关键词

**解决方案：**
- ✅ 创建 `hybrid_retriever.py`
- ✅ 实现 **BM25算法**（基于词频的检索）
- ✅ 实现 **混合检索策略**：
  - BM25权重：30%（精准词匹配）
  - 语义权重：70%（语义理解）
- ✅ 自动归一化和加权融合

**配置选项：**
```python
# config.py
USE_HYBRID_RETRIEVAL = True  # 是否使用混合检索
BM25_WEIGHT = 0.3           # BM25权重
SEMANTIC_WEIGHT = 0.7       # 语义检索权重
```

---

### 2. 添加答案来源信息

**实现内容：**
- ✅ 每个知识点包含：
  - **源文档名称**：`source_doc`
  - **文档类型**：`type` (.pdf, .docx等)
  - **片段索引**：`chunk_index`（第几段）
  - **片段类型**：`chunk_type`（paragraph/table/title_section）
  - **检索分数**：包括总分、BM25分、语义分

**返回格式：**
```python
{
    'question': '...',
    'knowledge_points': ['...'],  # 纯文本（向后兼容）
    'knowledge_points_detailed': [  # 新增：详细信息
        {
            'content': '知识点内容',
            'source': {
                'document': '文档名称',
                'type': 'pdf',
                'chunk_index': 0,
                'chunk_type': 'paragraph'
            },
            'score': 0.85,
            'score_details': {
                'total': 0.85,
                'bm25': 0.25,
                'semantic': 0.60
            }
        }
    ]
}
```

**命令行输出示例：**
```
[知识点 1]
【来源】文档: 中国太保2023年度业绩报告
       类型: pdf
       片段: 第5段
【得分】0.8532
       (BM25: 0.2156, 语义: 0.6376)
【内容】
2023年度...
```

---

### 3. 修复.doc文档解析问题

**问题原因：**
- `python-docx` 仅支持 `.docx` 格式
- 不支持旧版 `.doc` 格式（Microsoft Word 97-2003）

**解决方案：**
- ✅ 添加 `.doc` 格式支持到 `supported_formats`
- ✅ 尝试解析 `.doc`，失败时给出明确提示
- ✅ 提示用户转换方法：
  1. 使用Microsoft Word另存为.docx
  2. 使用在线转换工具
  3. 转换后重新放入dataset目录

**日志输出：**
```
WARNING: 检测到旧版.doc格式：文档名.doc
ERROR: 无法解析.doc文件
建议：
1. 使用Microsoft Word将文件另存为.docx格式
2. 或使用在线转换工具
3. 转换后重新放入dataset目录
```

---

### 4. 配置多模型选择

**已配置的模型：**

**【推荐】选项1：BGE（BAAI/bge-large-zh-v1.5）**
```python
SENTENCE_TRANSFORMER_MODEL = "BAAI/bge-large-zh-v1.5"
```
- ✅ **中文效果最佳**
- ✅ 专为中文优化
- ✅ 适合金融领域

**选项2：text2vec（轻量级）**
```python
SENTENCE_TRANSFORMER_MODEL = "shibing624/text2vec-base-chinese"
```
- 速度快
- 资源占用少

**选项3：text2vec-large**
```python
SENTENCE_TRANSFORMER_MODEL = "GanymedeNil/text2vec-large-chinese"
```
- 平衡效果和速度

**选项4：多语言模型（不推荐）**
```python
SENTENCE_TRANSFORMER_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
```

**选项5：SimCSE（可测试）**
```python
SENTENCE_TRANSFORMER_MODEL = "princeton-nlp/sup-simcse-bert-base-uncased"
```

**切换方法：**
在 `config.py` 中注释/取消注释相应行即可

---

### 5. 优化知识分块参数

**原参数：**
- 分块大小：800字
- 重叠：100字

**优化后：**
- ✅ 分块大小：**500字**（更精准，减少无关内容）
- ✅ 重叠：**150字**（更好保持上下文连贯性）

**配置：**
```python
# config.py
CHUNK_SIZE = 500      # 从800→500
CHUNK_OVERLAP = 150   # 从100→150
```

**效果：**
- 更精准的知识片段
- 更好的上下文保持
- 减少答非所问

---

## 🔄 需要执行的操作

### 1. 重新构建知识库

由于修改了：
- 分块大小（800→500）
- 向量模型（BGE）

**必须重新构建知识库：**

```bash
# 方法1：运行main.py（自动重建）
python main.py

# 方法2：通过quick_start.py
python quick_start.py
```

**预期效果：**
- 知识片段数量会增加（500字/片段）
- 首次运行需要下载BGE模型（约1.3GB）
- 构建时间约5-10分钟

---

### 2. 处理.doc文档

**检查dataset目录：**
```bash
# 查找.doc文件
dir dataset\*.doc /s
```

**转换方法：**

**方法1：Microsoft Word**
1. 打开.doc文件
2. 文件 → 另存为
3. 选择格式：Word文档(*.docx)
4. 保存

**方法2：在线转换**
- https://www.zamzar.com/
- https://www.online-convert.com/
- https://convertio.co/zh/doc-docx/

**方法3：LibreOffice（免费）**
1. 安装LibreOffice
2. 打开.doc文件
3. 另存为.docx

---

## 📊 性能对比

| 指标 | 改进前 | 改进后 | 说明 |
|------|--------|--------|------|
| 检索方式 | 纯语义向量 | BM25+语义混合 | ✅ 更精准 |
| 分块大小 | 800字 | 500字 | ✅ 更细粒度 |
| 片段重叠 | 100字 | 150字 | ✅ 更好上下文 |
| 向量模型 | multilingual | BGE-zh | ✅ 中文专用 |
| 来源信息 | ❌ 无 | ✅ 完整 | ✅ 可溯源 |
| .doc支持 | ❌ 失败 | ⚠️ 提示转换 | ⚠️ 需手动转换 |
| 相似度阈值 | 0.3 | 0.5 | ✅ 过滤噪音 |

---

## 🎯 使用建议

### 1. 首次使用

```bash
# 1. 确保.doc文件已转换为.docx
# 2. 重新构建知识库（使用BGE模型）
python main.py

# 3. 等待模型下载和索引构建
# 4. 查看输出结果（包含来源信息）
```

### 2. 模型选择

**如果追求最佳效果：**
```python
SENTENCE_TRANSFORMER_MODEL = "BAAI/bge-large-zh-v1.5"  # 推荐
```

**如果计算资源有限：**
```python
SENTENCE_TRANSFORMER_MODEL = "shibing624/text2vec-base-chinese"
```

### 3. 检索策略调整

**如果结果太泛：**
```python
SIMILARITY_THRESHOLD = 0.6  # 提高阈值
BM25_WEIGHT = 0.4  # 增加词频权重
SEMANTIC_WEIGHT = 0.6  # 减少语义权重
```

**如果召回率太低：**
```python
SIMILARITY_THRESHOLD = 0.4  # 降低阈值
BM25_WEIGHT = 0.2  # 减少词频权重
SEMANTIC_WEIGHT = 0.8  # 增加语义权重
```

---

## 📝 文件清单

### 新增文件：
- `hybrid_retriever.py` - BM25+语义混合检索器

### 修改文件：
- `config.py` - 添加混合检索配置、模型选择、优化分块参数
- `retrieval_ranking.py` - 集成混合检索、添加来源信息
- `document_parser.py` - 支持.doc格式、优化分块
- `main.py` - 输出来源信息、详细分数
- `knowledge_chunker.py` - 使用新分块参数（500/150）

---

## ⚠️ 注意事项

1. **必须重新构建知识库**，否则使用旧的800字分块
2. **.doc文件需要手动转换为.docx**
3. **BGE模型首次下载需要时间**（约1.3GB）
4. **建议在较好的网络环境下运行**
5. **如果内存不足，可以切换到text2vec-base模型**

---

## 🐛 问题排查

### 问题1：模型下载失败
```
解决方案：
1. 检查网络连接
2. 使用国内镜像：
   export HF_ENDPOINT=https://hf-mirror.com
3. 或手动下载模型到本地
```

### 问题2：.doc文件仍然解析失败
```
解决方案：
1. 确认文件确实是.doc格式
2. 使用Word/LibreOffice转换为.docx
3. 确保转换后的文件可以正常打开
4. 重新运行系统
```

### 问题3：内存不足
```
解决方案：
1. 切换到轻量级模型：
   SENTENCE_TRANSFORMER_MODEL = "shibing624/text2vec-base-chinese"
2. 减少batch_size（在代码中修改）
3. 分批处理文档
```

---

## 📞 技术支持

如有问题，请提供：
1. 错误日志（output/system.log）
2. 使用的模型配置
3. dataset文档数量和格式
4. 系统配置（内存、CPU等）

